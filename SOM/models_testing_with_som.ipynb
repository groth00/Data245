{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestClassifier, \\\n",
    "    HistGradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
    "    recall_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, \\\n",
    "    BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "from imblearn.pipeline import make_pipeline as imblearn_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# helper functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# WITHOUT SAMPLING\n",
    "def fitEstimatorWithoutSampling(X_train, y_train, estimator):\n",
    "    p = imblearn_pipeline(MinMaxScaler(), estimator)\n",
    "    start = time()\n",
    "    print('Started fitting model...')\n",
    "    p.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    print(f'Finished training in {end - start} seconds.')\n",
    "    return p\n",
    "\n",
    "def fitMultipleEstimatorsWithoutSampling(X_train, y_train, estimator_dict):\n",
    "    fit_estimators = []\n",
    "    for name, estimator in estimator_dict.items():\n",
    "        fit_estimator = fitEstimatorWithoutSampling(\n",
    "            X_train, y_train, estimator = estimator)\n",
    "        fit_estimators.append(fit_estimator)\n",
    "    return fit_estimators\n",
    "\n",
    "def scoreEstimator(trained_estimator, X_test, y_test):\n",
    "    predictions = trained_estimator.predict(X_test)\n",
    "    print(recall_score(y_test, predictions))\n",
    "\n",
    "def scoreEstimator1(trained_estimator, X_test, y_test):\n",
    "    print(trained_estimator.score(X_test, y_test))\n",
    "    preds = trained_estimator.predict(X_test)\n",
    "    # print confusion matrix and plot a heatmap\n",
    "    confused = confusion_matrix(y_true = y_test, y_pred = preds)\n",
    "    print(confused)\n",
    "    # row0: class 0 recall, col0: class 0 precision (same for row1, col1)\n",
    "    print(classification_report(y_true = y_test, y_pred = preds))\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# imbalanced-learn functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def fitEstimatorWithSamplerWithCV(X, y, cv = None,\n",
    "        sampler = RandomUnderSampler(random_state = 111),\n",
    "        estimator = HistGradientBoostingClassifier(random_state = 111)):\n",
    "\n",
    "    model = imblearn_pipeline(MinMaxScaler(), sampler, estimator)\n",
    "    if cv is None:\n",
    "        cv = KFold(n_splits = 3, shuffle = True, random_state = 100)\n",
    "    results = cross_validate(model, X, y, cv = cv,\n",
    "                             return_train_score = True,\n",
    "                             return_estimator = True,\n",
    "                             verbose = 1,\n",
    "                             scoring = 'recall',\n",
    "                             n_jobs = -1)\n",
    "    print('Average recall and standard deviation \\n' +\n",
    "          f\"{results['test_score'].mean()} +/- {results['test_score'].std()}\")\n",
    "    bestEstimator = results['estimator'][np.argmax(results['test_score'])]\n",
    "    return bestEstimator\n",
    "\n",
    "def fitEstimatorWithSamplerWithoutCV(X_train, y_train,\n",
    "        sampler = RandomUnderSampler(random_state = 111),\n",
    "        estimator = HistGradientBoostingClassifier(random_state = 111)):\n",
    "    '''\n",
    "    default: use RandomUnderSampler, HistGradientBoostingClassifier\n",
    "    scale features -> under sample majority class -> fit estimator\n",
    "    '''\n",
    "    model = imblearn_pipeline(MinMaxScaler(), sampler, estimator)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def fitMultipleEstimators(X_train, y_train, estimator_dict,\n",
    "                          sampling_method = None):\n",
    "    if not sampling_method:\n",
    "        sampling_method = RandomUnderSampler(random_state = 111)\n",
    "    fit_estimators = []\n",
    "    for name, estimator in estimator_dict.items():\n",
    "        print(f'Started training {name} with {sampling_method}.')\n",
    "        start = time()\n",
    "        fit_estimator = fitEstimatorWithSamplerWithoutCV(\n",
    "            X_train, y_train, sampler = sampling_method, estimator = estimator)\n",
    "        end = time()\n",
    "        print(f'Finished training {name} in {end-start} seconds. \\n')\n",
    "        fit_estimators.append(fit_estimator)\n",
    "    return fit_estimators\n",
    "\n",
    "def scoreBalancedEstimator(estimator, X_test, y_test, verbose = 0):\n",
    "    '''\n",
    "    compute and return predictions\n",
    "    move metrics/plotting to a separate function\n",
    "    '''\n",
    "    name = estimator.steps[-1][0]\n",
    "    pred = estimator.predict(X_test)\n",
    "    if verbose == 0:\n",
    "        print(f'Recall for {name}: \\n',\n",
    "              recall_score(y_true = y_test, y_pred = pred), '\\n')\n",
    "    else:\n",
    "        print(classification_report(y_true = y_test, y_pred = pred), '\\n')\n",
    "    return pred\n",
    "\n",
    "def scoreMultipleEstimators(y_test, fitted_estimators):\n",
    "    '''\n",
    "    for each estimator, print the recall and store its predictions\n",
    "    return predictions for later use (other metrics)\n",
    "    '''\n",
    "    list_of_prediction_arrays = []\n",
    "    for estimator in fitted_estimators:\n",
    "        predicted = scoreBalancedEstimator(estimator, X_test, y_test)\n",
    "        list_of_prediction_arrays.append(predicted)\n",
    "    return list_of_prediction_arrays\n",
    "\n",
    "def showConfusionMatrixWithHeatmap(y_test, predictions, name = None):\n",
    "    confused = confusion_matrix(y_true = y_test, y_pred = predictions)\n",
    "    print(confused, '\\n')\n",
    "    ax = plt.subplot()\n",
    "    sns.heatmap(data = confused, fmt = ',', annot = True, ax = ax)\n",
    "    plt.show()\n",
    "    ax.set_title(f'Confusion Matrix for {name}')\n",
    "    ax.clear()\n",
    "    return None\n",
    "\n",
    "def printClassificationReport(y_test, predictions):\n",
    "    print(classification_report(y_true = y_test, y_pred = predictions))\n",
    "\n",
    "def printImbalancedClassificationReport(y_test, predictions):\n",
    "    print(classification_report_imbalanced(y_test, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# read data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "X = pd.read_csv('SOM_dimensions_20x20_0.01_1000.csv')\n",
    "X2 = pd.read_csv('SOM_dimensions_30x30_0.01_1000.csv')\n",
    "X3 = pd.read_csv('SOM_dimensions_20x20_0.01_2000.csv')\n",
    "y = pd.read_csv('y.csv')\n",
    "y = y.values.reshape(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X) == len(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size = 0.75, random_state = 111, shuffle = True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# testing individual models without Sampling\n",
    "## Reduced dimensions with SOM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "estimator_dict = {\n",
    "    'LR': LogisticRegression(max_iter = 100,\n",
    "                             n_jobs = -1,\n",
    "                             random_state = 111,\n",
    "                             solver = 'saga'),\n",
    "    'DT': DecisionTreeClassifier(random_state = 111),\n",
    "    'ANN': MLPClassifier(learning_rate = 'invscaling',\n",
    "                         random_state = 111,\n",
    "                         early_stopping = True),\n",
    "    'SVC': LinearSVC(dual = False,\n",
    "                     random_state = 111,\n",
    "                     max_iter = 1000),\n",
    "    'SGDC': SGDClassifier(max_iter = 1000, verbose = 0,\n",
    "                          n_jobs = -1, random_state = 111,\n",
    "                          learning_rate = 'optimal',\n",
    "                          early_stopping = True,\n",
    "                          )\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started fitting model...\n",
      "Finished training in 10.78075885772705 seconds.\n",
      "Started fitting model...\n",
      "Finished training in 1.1120450496673584 seconds.\n",
      "Started fitting model...\n",
      "Finished training in 83.8403069972992 seconds.\n",
      "Started fitting model...\n",
      "Finished training in 0.7206249237060547 seconds.\n",
      "Started fitting model...\n",
      "Finished training in 2.9742298126220703 seconds.\n"
     ]
    }
   ],
   "source": [
    "fitted = fitMultipleEstimatorsWithoutSampling(X_train, y_train, estimator_dict)\n",
    "\n",
    "# random state = 111 for estimator and sampler\n",
    "\n",
    "# Finished training LR in 16.586179971694946 seconds.\n",
    "# Finished training DT in 17.770429849624634 seconds.\n",
    "# Finished training ANN in 180.04376673698425 seconds.\n",
    "# Finished training SVC in 6.3358142375946045 seconds.\n",
    "# Finished training SGDC in 3.45185923576355 seconds."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Score - Multiple Estimators Without Sampling\n",
    "## Same low recall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for estimator in fitted:\n",
    "    scoreEstimator(estimator, X_test, y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# testing individual models with Sampling\n",
    "## Reduced dimensions with SOM 20*20 0.01 1000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training LR with RandomUnderSampler(random_state=111).\n",
      "Finished training LR in 4.433549880981445 seconds. \n",
      "\n",
      "Started training DT with RandomUnderSampler(random_state=111).\n",
      "Finished training DT in 0.932549238204956 seconds. \n",
      "\n",
      "Started training ANN with RandomUnderSampler(random_state=111).\n",
      "Finished training ANN in 78.940190076828 seconds. \n",
      "\n",
      "Started training SVC with RandomUnderSampler(random_state=111).\n",
      "Finished training SVC in 0.7110216617584229 seconds. \n",
      "\n",
      "Started training SGDC with RandomUnderSampler(random_state=111).\n",
      "Finished training SGDC in 1.3927083015441895 seconds. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "fitted_s_nl = fitMultipleEstimators(X_train, y_train, estimator_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Score - individual models with sampling\n",
    "## Reduced dimensions with SOM\n",
    "About 5% improvement in recall in average."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for logisticregression: \n",
      " 0.6840118570492822 \n",
      "\n",
      "Recall for decisiontreeclassifier: \n",
      " 0.705660963884849 \n",
      "\n",
      "Recall for mlpclassifier: \n",
      " 0.6948586146792046 \n",
      "\n",
      "Recall for linearsvc: \n",
      " 0.6844448391859936 \n",
      "\n",
      "Recall for sgdclassifier: \n",
      " 0.6981337359697135 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "individual_predictions2 = scoreMultipleEstimators(y_test, fitted_s_nl)\n",
    "\n",
    "# Recall for logisticregression:\n",
    "#  0.6314433848100984\n",
    "\n",
    "# Recall for decisiontreeclassifier:\n",
    "#  0.5609228070564987\n",
    "\n",
    "# Recall for mlpclassifier:\n",
    "#  0.6917611270858082\n",
    "\n",
    "# Recall for linearsvc:\n",
    "#  0.6280461403528249\n",
    "\n",
    "# Recall for sgdclassifier:\n",
    "#  0.6448769331542193"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reduced dimensions with SOM 30*30 0.01 1000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training LR with RandomUnderSampler(random_state=111).\n",
      "Finished training LR in 5.485041856765747 seconds. \n",
      "\n",
      "Started training DT with RandomUnderSampler(random_state=111).\n",
      "Finished training DT in 0.8427209854125977 seconds. \n",
      "\n",
      "Started training ANN with RandomUnderSampler(random_state=111).\n",
      "Finished training ANN in 130.44076204299927 seconds. \n",
      "\n",
      "Started training SVC with RandomUnderSampler(random_state=111).\n",
      "Finished training SVC in 0.9655489921569824 seconds. \n",
      "\n",
      "Started training SGDC with RandomUnderSampler(random_state=111).\n",
      "Finished training SGDC in 2.062833070755005 seconds. \n",
      "\n",
      "Recall for logisticregression: \n",
      " 0.6859991340357265 \n",
      "\n",
      "Recall for decisiontreeclassifier: \n",
      " 0.6464978406403695 \n",
      "\n",
      "Recall for mlpclassifier: \n",
      " 0.6395923306651272 \n",
      "\n",
      "Recall for linearsvc: \n",
      " 0.6859991340357265 \n",
      "\n",
      "Recall for sgdclassifier: \n",
      " 0.7348706049537598 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X2, y, train_size = 0.75, random_state = 111, shuffle = True)\n",
    "\n",
    "fitted_s_nl = fitMultipleEstimators(X_train, y_train, estimator_dict)\n",
    "\n",
    "individual_predictions2 = scoreMultipleEstimators(y_test, fitted_s_nl)\n",
    "\n",
    "# Recall for logisticregression:\n",
    "#  0.6314433848100984\n",
    "\n",
    "# Recall for decisiontreeclassifier:\n",
    "#  0.5609228070564987\n",
    "\n",
    "# Recall for mlpclassifier:\n",
    "#  0.6917611270858082\n",
    "\n",
    "# Recall for linearsvc:\n",
    "#  0.6280461403528249\n",
    "\n",
    "# Recall for sgdclassifier:\n",
    "#  0.6448769331542193\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reduced dimensions with SOM 20*20 0.01 2000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training LR with RandomUnderSampler(random_state=111).\n",
      "Finished training LR in 5.453662395477295 seconds. \n",
      "\n",
      "Started training DT with RandomUnderSampler(random_state=111).\n",
      "Finished training DT in 1.0550477504730225 seconds. \n",
      "\n",
      "Started training ANN with RandomUnderSampler(random_state=111).\n",
      "Finished training ANN in 164.3074278831482 seconds. \n",
      "\n",
      "Started training SVC with RandomUnderSampler(random_state=111).\n",
      "Finished training SVC in 1.0049090385437012 seconds. \n",
      "\n",
      "Started training SGDC with RandomUnderSampler(random_state=111).\n",
      "Finished training SGDC in 1.9280917644500732 seconds. \n",
      "\n",
      "Recall for logisticregression: \n",
      " 0.5923528693393136 \n",
      "\n",
      "Recall for decisiontreeclassifier: \n",
      " 0.5694714287300301 \n",
      "\n",
      "Recall for mlpclassifier: \n",
      " 0.5597903922374075 \n",
      "\n",
      "Recall for linearsvc: \n",
      " 0.5923528693393136 \n",
      "\n",
      "Recall for sgdclassifier: \n",
      " 0.5310692438355556 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X3, y, train_size = 0.75, random_state = 111, shuffle = True)\n",
    "\n",
    "fitted_s_nl = fitMultipleEstimators(X_train, y_train, estimator_dict)\n",
    "\n",
    "individual_predictions2 = scoreMultipleEstimators(y_test, fitted_s_nl)\n",
    "\n",
    "# Recall for logisticregression:\n",
    "#  0.6314433848100984\n",
    "\n",
    "# Recall for decisiontreeclassifier:\n",
    "#  0.5609228070564987\n",
    "\n",
    "# Recall for mlpclassifier:\n",
    "#  0.6917611270858082\n",
    "\n",
    "# Recall for linearsvc:\n",
    "#  0.6280461403528249\n",
    "\n",
    "# Recall for sgdclassifier:\n",
    "#  0.6448769331542193"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ensemble methods from sklearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "ensembles = {\n",
    "    'HGBC': HistGradientBoostingClassifier(random_state = 111),\n",
    "    'RF': RandomForestClassifier(\n",
    "        n_estimators = 100, max_depth = None, bootstrap = True,\n",
    "        oob_score = True, n_jobs = -1, random_state = 111)\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fitted_ensembles = fitMultipleEstimators(X_train, y_train, ensembles)\n",
    "\n",
    "# random state = 111 for estimator and sampler\n",
    "\n",
    "# Finished training HGBC in 14.294695377349854 seconds.\n",
    "# Finished training RF in 169.3908851146698 seconds."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for histgradientboostingclassifier: \n",
      " 0.696868095877788 \n",
      "\n",
      "Recall for randomforestclassifier: \n",
      " 0.7070820334617477 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_predictions = scoreMultipleEstimators(y_test, fitted_ensembles)\n",
    "\n",
    "# Recall for histgradientboostingclassifier:\n",
    "#  0.6760516469974354\n",
    "\n",
    "# Recall for randomforestclassifier:\n",
    "#  0.6551907896928048"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training HGBC with RandomUnderSampler(random_state=111).\n",
      "Finished training HGBC in 5.309612035751343 seconds. \n",
      "\n",
      "Started training RF with RandomUnderSampler(random_state=111).\n",
      "Finished training RF in 15.020652055740356 seconds. \n",
      "\n",
      "Recall for histgradientboostingclassifier: \n",
      " 0.6244046495620219 \n",
      "\n",
      "Recall for randomforestclassifier: \n",
      " 0.647297192277375 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X2, y, train_size = 0.75, random_state = 111, shuffle = True)\n",
    "fitted_ensembles = fitMultipleEstimators(X_train, y_train, ensembles)\n",
    "ensemble_predictions = scoreMultipleEstimators(y_test, fitted_ensembles)\n",
    "\n",
    "# Recall for histgradientboostingclassifier:\n",
    "#  0.6760516469974354\n",
    "\n",
    "# Recall for randomforestclassifier:\n",
    "#  0.6551907896928048"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training HGBC with RandomUnderSampler(random_state=111).\n",
      "Finished training HGBC in 4.585388660430908 seconds. \n",
      "\n",
      "Started training RF with RandomUnderSampler(random_state=111).\n",
      "Finished training RF in 14.0642569065094 seconds. \n",
      "\n",
      "Recall for histgradientboostingclassifier: \n",
      " 0.5627657566640392 \n",
      "\n",
      "Recall for randomforestclassifier: \n",
      " 0.5698266961242547 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X3, y, train_size = 0.75, random_state = 111, shuffle = True)\n",
    "fitted_ensembles = fitMultipleEstimators(X_train, y_train, ensembles)\n",
    "ensemble_predictions = scoreMultipleEstimators(y_test, fitted_ensembles)\n",
    "\n",
    "# Recall for histgradientboostingclassifier:\n",
    "#  0.6760516469974354\n",
    "\n",
    "# Recall for randomforestclassifier:\n",
    "#  0.6551907896928048"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ensemble methods from imbalanced-learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started fitting model...\n",
      "Finished training in 6.982941150665283 seconds.\n",
      "Started fitting model...\n",
      "Finished training in 35.670021057128906 seconds.\n",
      "Started fitting model...\n",
      "Finished training in 27.153301000595093 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/imblearn/pipeline.py:266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "imbalanced_ensembles = {\n",
    "    'BalancedBagging': BalancedBaggingClassifier(n_jobs = -1,\n",
    "                                                 random_state = 111),\n",
    "    'BalancedRF': BalancedRandomForestClassifier(n_jobs = -1,\n",
    "                                                 random_state = 111),\n",
    "    'EasyEnsemble': EasyEnsembleClassifier(n_jobs = -1,\n",
    "                                           random_state = 111),\n",
    "    }\n",
    "\n",
    "fitted_imbalanced = fitMultipleEstimatorsWithoutSampling(\n",
    "    X_train, y_train, imbalanced_ensembles)\n",
    "\n",
    "# random state = 111 for estimators\n",
    "# Finished training BalancedBagging in 103.74243307113647 seconds.\n",
    "# Finished training BalancedRF in 152.8362331390381 seconds.\n",
    "# Finished training EasyEnsemble in 490.34461307525635 seconds."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for balancedbaggingclassifier: \n",
      " 0.7014865720027089 \n",
      "\n",
      "Recall for balancedrandomforestclassifier: \n",
      " 0.7026411910339392 \n",
      "\n",
      "Recall for easyensembleclassifier: \n",
      " 0.677894596604976 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "imbalanced_ensemble_predictions = scoreMultipleEstimators(\n",
    "    y_test, fitted_imbalanced)\n",
    "\n",
    "# Recall for balancedbaggingclassifier:\n",
    "#  0.40160758495886667\n",
    "\n",
    "# Recall for balancedrandomforestclassifier:\n",
    "#  0.6577331719827251\n",
    "\n",
    "# Recall for easyensembleclassifier:\n",
    "#  0.6693237707193055\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# new: VotingClassifier and StackedClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7152087751046373\n"
     ]
    }
   ],
   "source": [
    "individual_pipelines = [imblearn_pipeline(MinMaxScaler(),\n",
    "                   RandomUnderSampler(random_state = 111),\n",
    "                   estimator) for estimator in estimator_dict.values()]\n",
    "\n",
    "# majority vote (hard)\n",
    "# uniform weights for each classifier\n",
    "v = VotingClassifier(estimators = list(zip(\n",
    "    [k for k in estimator_dict.keys()], individual_pipelines)),\n",
    "                     voting = 'hard',\n",
    "                     weights = None,\n",
    "                     n_jobs = -1,\n",
    "                     verbose = True)\n",
    "\n",
    "v.fit(X_train, y_train)\n",
    "voter_predictions = v.predict(X_test)\n",
    "\n",
    "# better than DT, SVC, SGDC, slightly better than LR, but worse than MLP\n",
    "print(recall_score(y_test, voter_predictions))\n",
    "# 0.6375606452544048\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "individual_pipelines = [imblearn_pipeline(MinMaxScaler(),\n",
    "                   RandomUnderSampler(random_state = 111),\n",
    "                   estimator) for estimator in estimator_dict.values()]\n",
    "\n",
    "# majority vote (hard)\n",
    "# uniform weights for each classifier\n",
    "v = VotingClassifier(estimators = list(zip(\n",
    "    [k for k in estimator_dict.keys()], individual_pipelines)),\n",
    "                     voting = 'hard',\n",
    "                     weights = None,\n",
    "                     n_jobs = -1,\n",
    "                     verbose = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7160081267416429\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X2, y, train_size = 0.75, random_state = 111, shuffle = True)\n",
    "\n",
    "v.fit(X_train, y_train)\n",
    "voter_predictions = v.predict(X_test)\n",
    "\n",
    "# better than DT, SVC, SGDC, slightly better than LR, but worse than MLP\n",
    "print(recall_score(y_test, voter_predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}