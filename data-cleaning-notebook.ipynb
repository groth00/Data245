{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, MissingIndicator\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking features\n",
    "f1 = {'addr_state', 'annual_inc', 'application_type', 'dti', 'emp_length', \n",
    "      'fico_range_high', 'fico_range_low',  'grade', 'home_ownership', \n",
    "      'initial_list_status', 'installment', 'int_rate', 'loan_amnt', \n",
    "      'loan_status', 'mort_acc', 'open_acc', 'pub_rec', \n",
    "      'pub_rec_bankruptcies', 'purpose', 'revol_bal', 'revol_util', \n",
    "      'sub_grade', 'term', 'title', 'total_acc', 'verification_status'}\n",
    "\n",
    "f2 = {'acc_now_delinq', 'annual_inc', 'delinq_2yrs', 'dti', 'emp_length', \n",
    "      'fico_range_high', 'fico_range_low', 'home_ownership', 'il_util', \n",
    "      'installment', 'int_rate', 'loan_amnt', 'loan_status', \n",
    "      'max_bal_bc', 'mths_since_last_major_derog', 'num_accts_ever_120_pd', \n",
    "      'num_actv_rev_tl', 'num_rev_accts', 'num_sats', 'num_tl_90g_dpd_24m', \n",
    "      'open_act_il', 'pct_tl_nvr_dlq', 'pub_rec', 'pub_rec_bankruptcies', \n",
    "      'revol_util', 'sub_grade', 'tax_liens', 'tot_coll_amt', \n",
    "      'hardship_flag', 'hardship_status', 'hardship_length', \n",
    "      'debt_settlement_flag' }\n",
    "\n",
    "f3 = {'addr_state', 'annual_inc', 'application_type', 'dti', \n",
    "      'earliest_cr_line', 'emp_length', 'emp_title', 'fico_range_high', \n",
    "      'fico_range_low', 'grade', 'hardship_flag', 'home_ownership', \n",
    "      'id', 'initial_list_status', 'installment', 'int_rate', 'issue_d', \n",
    "      'loan_amnt', 'loan_status', 'mort_acc', 'open_acc', 'pub_rec', \n",
    "      'pub_rec_bankruptcies', 'purpose', 'revol_bal', 'revol_util', \n",
    "      'sub_grade', 'tax_liens', 'term', 'title', 'total_acc', \n",
    "      'verification_status'}\n",
    "\n",
    "f4 = {'acc_now_delinq', 'acc_open_past_24mths', 'addr_state', \n",
    "      'annual_inc',  'all_util', 'bc_util', 'revol_util', 'dti', \n",
    "      'emp_length', 'emp_title', 'fico_range_high', 'fico_range_low', \n",
    "      'home_ownership', 'inq_last_12m', 'int_rate', 'loan_amnt', \n",
    "      'mort_acc', 'mths_since_recent_inq', 'num_accts_ever_120_pd', \n",
    "      'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', \n",
    "      'open_acc_6m', 'open_il_24m', 'open_rv_24m', 'percent_bc_gt_75', \n",
    "      'pub_rec', 'pub_rec_bankruptcies', 'term', 'total_acc', \n",
    "      'verification_status', 'loan_status'}\n",
    "\n",
    "features = f1 | f2 | f3 | f4\n",
    "to_remove = {'hardship_status', 'hardship_length', 'tot_coll_amt',\n",
    "             'mths_since_last_major_derog', 'id', 'grade', 'emp_title',\n",
    "             'issue_d', 'title', 'debt_settlement_flag', 'hardship_flag'}\n",
    "to_use = features - to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file\n",
    "df = pd.read_csv('loandata/Loan2007-2020Q3.gzip', usecols = to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat int_rate and revol_util into float\n",
    "pattern = r\"\\s{0,}(\\d{1,}\\.?\\d{0,})\\%\"\n",
    "replace = lambda x: x.group(1)\n",
    "cols_to_replace = ['int_rate', 'revol_util']\n",
    "for col in cols_to_replace:\n",
    "    df[col] = df[col].astype(str)\n",
    "    df[col] = df[col].str.replace(pat = pattern, repl = replace, \n",
    "                                      regex = True)\n",
    "    df[col] = df[col].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure dti > 0\n",
    "df.drop(index = df[df['dti'] < 0].index, axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fico ranges -> fico score (average)\n",
    "df['fico_score'] = df['fico_range_low'] + \\\n",
    "    df['fico_range_high'] // 2\n",
    "df.drop(['fico_range_low', 'fico_range_high'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check numerical variables\n",
    "num_vars = df.columns[df.dtypes == 'float64']\n",
    "d = df[num_vars].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace outliers\n",
    "# find cols with extreme outliers \n",
    "idx_series = d.apply(lambda x: x['50%'] != 0 and \\\n",
    "                x['max'] > (5 * x['75%'] - x['25%']), axis = 0)\n",
    "cols_to_adjust = d.columns[idx_series.values == True]\n",
    "\n",
    "# remove rows with extreme outliers: 10 * (Q3 - Q1)\n",
    "for col in cols_to_adjust:\n",
    "    thresh = df[col].quantile(0.75) - df[col].quantile(0.25)\n",
    "    to_remove = df[df[col] > 10 * thresh].index\n",
    "    df.drop(to_remove, axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check result of outlier removal\n",
    "pd.set_option('max_columns', 38)\n",
    "print(df[num_vars].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Variables\n",
    "cat_vars = df.columns[df.dtypes == 'object']\n",
    "\n",
    "# emp_length -> int\n",
    "# see arg na_action; avoid applying to missing values & keep them as NaN\n",
    "df['employment_len'] = df['emp_length'].map(\n",
    "    {'< 1 year': 0,\n",
    "     '1 year': 1,\n",
    "     '2 years': 2,\n",
    "     '3 years': 3,\n",
    "     '4 years': 4,\n",
    "     '5 years': 5,\n",
    "     '6 years': 6,\n",
    "     '7 years': 7,\n",
    "     '8 years': 8,\n",
    "     '9 years': 9,\n",
    "     '10+ years': 10})\n",
    "df.drop(['emp_length'], axis = 1, inplace = True)\n",
    "\n",
    "# credit line -> year \n",
    "pattern = r\"\\w+\\-(\\d{4})\"\n",
    "replace = lambda x: x.group(1)\n",
    "df['earliest_cr_line'] = df['earliest_cr_line'].str.replace(\n",
    "    pat = pattern, repl = replace, regex = True)\n",
    "df['earliest_cr_line'] = df['earliest_cr_line'].astype('float64')\n",
    "\n",
    "# home ownership -> consolidate categories ANY, OTHER, NONE\n",
    "df['home_status'] = df['home_ownership'].map(\n",
    "    {'MORTGAGE': 'MORTGAGE',\n",
    "     'RENT': 'RENT',\n",
    "     'OWN': 'OWN',\n",
    "     'OTHER': 'OTHER',\n",
    "     'ANY': 'OTHER',\n",
    "     'NONE': 'OTHER'})\n",
    "df.drop(labels = ['home_ownership'], axis = 1, inplace = True)\n",
    "\n",
    "# loan_status -> binary label (Paid Off: 0, Charged Off: 1)\n",
    "df['y'] = df['loan_status']\\\n",
    "    .map({'Fully Paid': 0, 'Charged Off': 1})\n",
    "df.dropna(subset = ['y'], axis = 0, inplace = True)\n",
    "df.drop(['loan_status'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot numerical vars\n",
    "to_plot = df.sample(frac = 0.05, random_state = 111)\n",
    "tp_num_vars = to_plot.select_dtypes('float64')\n",
    "y_to_plot = to_plot['y'].astype(str)\n",
    "for col in tp_num_vars.columns:\n",
    "    ax = plt.subplot()\n",
    "    sns.boxplot(data = tp_num_vars, x = col, y = y_to_plot, ax = ax)\n",
    "    ax.set_title(f'{col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot categorical vars with countplot\n",
    "tp_cat_vars = to_plot.select_dtypes('object')\n",
    "for col in tp_cat_vars.columns:\n",
    "    ax = plt.subplot()\n",
    "    o = to_plot[col].value_counts().index\n",
    "    sns.countplot(data = tp_cat_vars, y = col, order = o, \n",
    "                  hue = y_to_plot, ax = ax)\n",
    "    ax.set_ylabel(f'{col}', fontsize = 9)\n",
    "    ax.set_yticklabels(labels = o, rotation = 0, fontsize = 7)\n",
    "    ax.legend(loc = 'lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with missing values\n",
    "missing = df.isna().sum().apply(lambda x: x/df.shape[0] * 100)\n",
    "print(missing[missing > 0].sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot vars with missing values\n",
    "cols_with_missing_vals = missing[missing > 0]\\\n",
    "    .sort_values(ascending = False).index\n",
    "\n",
    "for col in cols_with_missing_vals:\n",
    "    g = sns.histplot(x = to_plot[col])\n",
    "    plt.show()\n",
    "    g.clear()\n",
    "\n",
    "# %% Imputing all_util with mean\n",
    "# i = SimpleImputer(strategy = 'mean')\n",
    "# df['all_util'] = i.fit_transform(df['all_util'].values.reshape(-1, 1))\n",
    "# print(df['all_util'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MissingIndicator\n",
    "m = MissingIndicator(features = 'missing-only')\n",
    "m.fit(df)\n",
    "indicators = m.transform(df)\n",
    "col_names = [name + '_missing' for name in missing[missing > 0].index]\n",
    "# this is a dataframe of booleans\n",
    "ind = pd.DataFrame(indicators, columns = col_names)\n",
    "# convert it to int (False (not missing) -> 0, True (missing) -> 1)\n",
    "ind = ind.astype(int)\n",
    "\n",
    "# %% Impute with IterativeImputer + DecisionTreeRegressor\n",
    "e = DecisionTreeRegressor(max_features = 'sqrt', \n",
    "                          max_depth = 3, random_state = 111)\n",
    "imp = IterativeImputer(estimator = e)\n",
    "\n",
    "num_vars = df[df.columns[df.dtypes == 'float64']]\n",
    "\n",
    "# impute based on existing numerical variables\n",
    "# it takes too long when using all variables \n",
    "imp.fit(num_vars)\n",
    "imputed = imp.transform(num_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical -> numerical and rejoin data\n",
    "X = pd.DataFrame(imputed, columns = num_vars.columns)\n",
    "\n",
    "cat_vars = df[df.columns[df.dtypes == 'object']]\n",
    "dummies = pd.get_dummies(cat_vars)\n",
    "\n",
    "# separate y\n",
    "y = X['y']\n",
    "X.drop('y', axis = 1, inplace = True)\n",
    "\n",
    "# had problems joining because of indexes so reset all of them\n",
    "X.reset_index(drop = True, inplace = True)\n",
    "dummies.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# join dummy variables with numerical variables\n",
    "cleaned_data = X.join(dummies)\n",
    "\n",
    "cleaned_data.reset_index(drop = True, inplace = True)\n",
    "ind.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# join missing_indicator variables with the rest of the variables\n",
    "with_mi = cleaned_data.join(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "with_mi.to_csv('X.csv.gzip', compression = 'gzip', index = None)\n",
    "y.to_csv('y.csv', index = None)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
