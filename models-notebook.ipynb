{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# from sklearn.pipeline import FeatureUnion, make_pipeline\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = pd.read_csv('X.csv.gzip', compression = 'gzip')\n",
    "y = pd.read_csv('y.csv')\n",
    "y = y.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale values\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler.fit(X)\n",
    "scaled_vars = pd.DataFrame(scaler.transform(X), columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_vars, y, train_size = 0.8, random_state = 111, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression (baseline w/all features)\n",
    "lr = LogisticRegression(solver = 'saga', n_jobs = -1, max_iter = 500)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "print(lr.score(X_test, y_test))\n",
    "\n",
    "confused = confusion_matrix(y_true = y_test, y_pred = lr_pred)\n",
    "print(confused)\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(confused, robust = True, annot = confused, fmt = ',',\n",
    "            ax = ax)\n",
    "ax.set_title('Confusion Matrix for LR')\n",
    "\n",
    "print(classification_report(y_test, lr_pred))\n",
    "\n",
    "# 0.8079179322659398\n",
    "\n",
    "# [[293111   3970]\n",
    "#  [ 66920   5060]]\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.81      0.99      0.89    297081\n",
    "#          1.0       0.56      0.07      0.12     71980\n",
    "\n",
    "#     accuracy                           0.81    369061\n",
    "#    macro avg       0.69      0.53      0.51    369061\n",
    "# weighted avg       0.76      0.81      0.74    369061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators = 100,\n",
    "    criterion = 'gini',\n",
    "    max_depth = None,\n",
    "    min_samples_split = 2,\n",
    "    min_samples_leaf = 1,\n",
    "    min_weight_fraction_leaf = 0.0,\n",
    "    bootstrap = True,\n",
    "    oob_score = True,\n",
    "    n_jobs = -1,\n",
    "    random_state = 111)\n",
    "\n",
    "start = time()\n",
    "print('Started fitting model...')\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "end = time()\n",
    "print('Finished training model.')\n",
    "print(f'It took {end - start} seconds to train the model.')\n",
    "\n",
    "print(rf.score(X_test, y_test))\n",
    "confused = confusion_matrix(y_true = y_test, y_pred = rf_pred)\n",
    "print(confused)\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(confused, robust = True, annot = confused, fmt = ',',\n",
    "            ax = ax)\n",
    "ax.set_title('Confusion Matrix for RF')\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "# 0.8072459566304757\n",
    "\n",
    "# [[293692   3389]\n",
    "#  [ 67749   4231]]\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.81      0.99      0.89    297081\n",
    "#          1.0       0.56      0.06      0.11     71980\n",
    "\n",
    "#     accuracy                           0.81    369061\n",
    "#    macro avg       0.68      0.52      0.50    369061\n",
    "# weighted avg       0.76      0.81      0.74    369061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the most important features based on RF\n",
    "importances = {X.columns[i]:val \\\n",
    "               for i,val in enumerate(rf.feature_importances_)}\n",
    "df_imp = pd.DataFrame.from_dict(importances, \n",
    "                                orient = 'index', \n",
    "                                columns = ['importance'])\n",
    "\n",
    "sorted_features = df_imp['importance'].sort_values(ascending = False)\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.barplot(y = sorted_features.values, x = sorted_features.index, ax = ax)\n",
    "ax.set_xticks([])\n",
    "ax.set_title('Feature Importances (for visual purposes)')\n",
    "\n",
    "# let's just use the features that have importance > 0.01\n",
    "# 32 variables\n",
    "best_features = sorted_features[sorted_features >= 0.01]\n",
    "o = best_features.index\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.barplot(x = best_features.values, y = o, order = o, ax = ax)\n",
    "ax.set_title('Most Important Features')\n",
    "ax.set_yticklabels(labels = o, rotation = 0, fontsize = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "feature_names = best_features.index\n",
    "X_new = X[feature_names]\n",
    "# X_new.to_csv('RF_important_features.csv.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model using joblib\n",
    "# dump(rf, 'rf_trained.joblib', compress = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo\n",
    "# use different proportions of train/test data\n",
    "# reduce features by using feature importance from RF/feature selection methods\n",
    "# cross-validation\n",
    "# different estimators\n",
    "# tune models (see GridSearch)\n",
    "# SMOTE libraries\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
