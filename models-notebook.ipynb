{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from joblib import dump\n",
    "from time import time\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestClassifier, \\\n",
    "    HistGradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
    "    recall_score\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, \\\n",
    "    BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "from imblearn.pipeline import make_pipeline as imblearn_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "X = pd.read_csv('X.csv.gzip', compression = 'gzip')\n",
    "y = pd.read_csv('y.csv')\n",
    "y = y.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "# scale data before fitting a single model\n",
    "def fitEstimator(estimator, X_train, y_train, pipeline = False):\n",
    "    if pipeline:\n",
    "        p = make_pipeline(MinMaxScaler(), estimator)\n",
    "    else:\n",
    "        p = estimator\n",
    "    start = time()\n",
    "    print('Started fitting model...')\n",
    "    p.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    print('Finished training model.')\n",
    "    print(f'It took {end - start} seconds to train the model.')\n",
    "    return p\n",
    "\n",
    "# score a single fitted model\n",
    "def scoreEstimator(trained_estimator, X_test, y_test):\n",
    "    print(trained_estimator.score(X_test, y_test))\n",
    "    preds = trained_estimator.predict(X_test)\n",
    "    # print confusion matrix and plot a heatmap\n",
    "    confused = confusion_matrix(y_true = y_test, y_pred = preds)\n",
    "    print(confused)\n",
    "    ax = plt.subplot()\n",
    "    # row0: class 0 recall, col0: class 0 precision (same for row1, col1)\n",
    "    sns.heatmap(data = confused, fmt = ',', annot = True, ax = ax)\n",
    "    ax.set_title('')\n",
    "    print(classification_report(y_true = y_test, y_pred = preds))\n",
    "    return None\n",
    "    \n",
    "# %%\n",
    "# train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size = 0.75, random_state = 111, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression (full features)\n",
    "lr = fitEstimator(\n",
    "    LogisticRegression(solver = 'saga', n_jobs = -1, max_iter = 500),\n",
    "    X_train, y_train)\n",
    "scoreEstimator(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest (full features)\n",
    "rf = fitEstimator(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators = 100, max_depth = None, bootstrap = True,\n",
    "        oob_score = True, n_jobs = -1, random_state = 111),\n",
    "    X_train, y_train)\n",
    "scoreEstimator(rf, X_test, y_test)\n",
    "\n",
    "# [[293692   3389]\n",
    "#  [ 67749   4231]]\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.81      0.99      0.89    297081\n",
    "#          1.0       0.56      0.06      0.11     71980\n",
    "\n",
    "#     accuracy                           0.81    369061\n",
    "#    macro avg       0.68      0.52      0.50    369061\n",
    "# weighted avg       0.76      0.81      0.74    369061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most important features based on RF\n",
    "importances = {X.columns[i]:val \\\n",
    "               for i,val in enumerate(rf.feature_importances_)}\n",
    "df_imp = pd.DataFrame.from_dict(importances, \n",
    "                                orient = 'index', \n",
    "                                columns = ['importance'])\n",
    "\n",
    "sorted_features = df_imp['importance'].sort_values(ascending = False)\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.barplot(y = sorted_features.values, x = sorted_features.index, ax = ax)\n",
    "ax.set_xticks([])\n",
    "ax.set_title('Feature Importances (for visual purposes)')\n",
    "\n",
    "# let's just use the features that have importance > 0.01 (32 variables)\n",
    "best_features = sorted_features[sorted_features >= 0.01]\n",
    "o = best_features.index\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.barplot(x = best_features.values, y = o, order = o, ax = ax)\n",
    "ax.set_title('Most Important Features')\n",
    "ax.set_yticklabels(labels = o, rotation = 0, fontsize = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save lower-dimensional data\n",
    "feature_names = best_features.index\n",
    "X_new = X[feature_names]\n",
    "# X_new.to_csv('RF_important_features.csv.gzip', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model using joblib\n",
    "# dump(rf, 'rf_trained.joblib', compress = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps\n",
    "# try reducing # of features using other feature selection methods\n",
    "\n",
    "# different methods: individual models, homogeneous ens, heterogeneous ens\n",
    "# individual: LinearSVC, MLP, LR, DT\n",
    "# homogeneous ensemble: GBDT, RF\n",
    "# heterogeneous ensemble: VotingClassifier, StackingClassifier\n",
    "\n",
    "# based on some testing, the individual models have similar recall (0.07-0.08)\n",
    "# need to use imbalanced-learn/smote-variants w/models\n",
    "\n",
    "# cross-validation, tune models (see GridSearch)\n",
    "# ex. VotingClassifier + GS, StackingClassifier + cv\n",
    "\n",
    "# finally, follow the approaches in the research papers \n",
    "# ex. SOM for consensus, clustering + alone, cluster + alone + consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing a few models + sampling methods on reduced data\n",
    "X = pd.read_csv('RF_important_features.csv.gzip', compression = 'gzip')\n",
    "y = pd.read_csv('y.csv')\n",
    "y = y.values.reshape(-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size = 0.75, random_state = 111, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HistGradientBoostingClassifier (fast, <1 min)\n",
    "p = fitEstimator(HistGradientBoostingClassifier(random_state = 0), X, y)\n",
    "scoreEstimator(p, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN (~9 minutes)\n",
    "mlp_model = fitEstimator(MLPClassifier(learning_rate = 'invscaling',\n",
    "                                       random_state = 0,\n",
    "                                       early_stopping = True), X, y)\n",
    "scoreEstimator(mlp_model, X_test, y_test)\n",
    "# both GB, ANN have similar results to LR, RF -> try imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced-learn \n",
    "# helper f for testing out samplers and estimators\n",
    "def fitEstimatorWithSamplerWithCV(X, y, cv = None, \n",
    "        sampler = RandomUnderSampler(random_state = 0),\n",
    "        estimator = HistGradientBoostingClassifier(random_state = 0)):\n",
    "    \n",
    "    model = imblearn_pipeline(sampler, estimator)\n",
    "    if cv is None:\n",
    "        cv = KFold(n_splits = 3, shuffle = True, random_state = 100)\n",
    "    results = cross_validate(model, X, y, cv = cv,\n",
    "                             return_train_score = True,\n",
    "                             return_estimator = True,\n",
    "                             verbose = 1,\n",
    "                             scoring = 'recall',\n",
    "                             n_jobs = -1)\n",
    "    print('Average recall and standard deviation \\n' +\n",
    "          f\"{results['test_score'].mean()} +/- {results['test_score'].std()}\")\n",
    "    bestEstimator = results['estimator'][np.argmax(results['test_score'])]\n",
    "    return bestEstimator\n",
    "\n",
    "def fitEstimatorWithSamplerWithoutCV(X_train, y_train, \n",
    "        sampler = RandomUnderSampler(random_state = 0),\n",
    "        estimator = HistGradientBoostingClassifier(random_state = 0)):\n",
    "    \n",
    "    model = imblearn_pipeline(sampler, estimator)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def scoreBalancedEstimator(estimator, X_test, y_test):\n",
    "    pred = estimator.predict(X_test)\n",
    "    confused = confusion_matrix(y_true = y_test, y_pred = pred)\n",
    "    print(confused)\n",
    "    ax = plt.subplot()\n",
    "    sns.heatmap(data = confused, fmt = ',', annot = True, ax = ax)\n",
    "    # print(classification_report(y_true = y_test, y_pred = cv_pred))\n",
    "    print(classification_report_imbalanced(y_true = y_test, y_pred = pred))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplest sampler is RandomUnderSampler; TomekLinks takes too long\n",
    "kfold = KFold(n_splits = 3, shuffle = True, random_state = 100)\n",
    "est = fitEstimatorWithSamplerWithCV(X = X, y = y, cv = kfold)\n",
    "scoreEstimator(est, X_test, y_test)\n",
    "\n",
    "# [[239923 131330]\n",
    "#  [ 28751  61322]]\n",
    "#                    pre       rec       spe        f1       geo       iba       sup\n",
    "\n",
    "#         0.0       0.89      0.65      0.68      0.75      0.66      0.44    371253\n",
    "#         1.0       0.32      0.68      0.65      0.43      0.66      0.44     90073\n",
    "\n",
    "# avg / total       0.78      0.65      0.67      0.69      0.66      0.44    461326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BalancedBaggingClassifier, also trying different n_estimators\n",
    "# recall doesn't improve much from 10 to 30 estimators (also takes more time)\n",
    "scores = []\n",
    "estimators = []\n",
    "for n in range(10, 60, 10):\n",
    "    bag = fitEstimator(BalancedBaggingClassifier(n_estimators = n,\n",
    "                                                 n_jobs = -1,\n",
    "                                                 random_state = 100),\n",
    "                       X_train, y_train)\n",
    "    pred = bag.predict(X_test)\n",
    "    scores.append(recall_score(y_true = y_test, y_pred = pred))\n",
    "    estimators.append(bag)\n",
    "    print(classification_report(y_test, pred))\n",
    "# [[293771  77482]\n",
    "#  [ 49144  40929]]\n",
    "#                    pre       rec       spe        f1       geo       iba       sup\n",
    "\n",
    "#         0.0       0.86      0.79      0.45      0.82      0.60      0.37    371253\n",
    "#         1.0       0.35      0.45      0.79      0.39      0.60      0.35     90073\n",
    "\n",
    "# avg / total       0.76      0.73      0.52      0.74      0.60      0.37    461326\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BalancedRandomForestClassifier is slightly worse than HGBC, but is fast\n",
    "# tried with 100 estimators, didn't make a difference\n",
    "brf = fitEstimator(BalancedRandomForestClassifier(n_estimators = 50,\n",
    "                                                  n_jobs = -1,\n",
    "                                                  random_state = 100,\n",
    "                                                  max_samples = 0.5),\n",
    "                   X_train, y_train)\n",
    "scoreEstimator(brf, X_test, y_test)\n",
    "# 0.6520898453588135\n",
    "# [[242935 128318]\n",
    "#  [ 32182  57891]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.88      0.65      0.75    371253\n",
    "#          1.0       0.31      0.64      0.42     90073\n",
    "\n",
    "#     accuracy                           0.65    461326\n",
    "#    macro avg       0.60      0.65      0.59    461326\n",
    "# weighted avg       0.77      0.65      0.69    461326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EasyEnsembleClassifier; took 8.3 minutes, worse than BalancedRF\n",
    "ee = fitEstimator(EasyEnsembleClassifier(n_estimators = 10,\n",
    "                                          n_jobs = -1,\n",
    "                                          random_state = 100),\n",
    "                   X_train, y_train)\n",
    "scoreEstimator(ee, X_test, y_test)\n",
    "# It took 492.42835903167725 seconds to train the model.\n",
    "# 0.6411431395585768\n",
    "# [[235479 135774]\n",
    "#  [ 29776  60297]]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.89      0.63      0.74    371253\n",
    "#          1.0       0.31      0.67      0.42     90073\n",
    "\n",
    "#     accuracy                           0.64    461326\n",
    "#    macro avg       0.60      0.65      0.58    461326\n",
    "# weighted avg       0.77      0.64      0.68    461326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual models with RandomUnderSampler\n",
    "# LR i tried 500,1000,2000 iterations, it never converged\n",
    "# might as well stick with the default (100) to save time\n",
    "estimator_list = {\n",
    "    'LR': LogisticRegression(max_iter = 100, \n",
    "                             n_jobs = -1, \n",
    "                             random_state = 111,\n",
    "                             solver = 'saga'),\n",
    "    'DT': DecisionTreeClassifier(random_state = 111),\n",
    "    'ANN': MLPClassifier(learning_rate = 'invscaling',\n",
    "                         random_state = 111,\n",
    "                         early_stopping = True),\n",
    "    'SVC': LinearSVC(dual = False,\n",
    "                     random_state = 111,\n",
    "                     max_iter = 1000)\n",
    "    }\n",
    "\n",
    "fit_estimators = []\n",
    "for name, estimator in estimator_list.items():\n",
    "    print(f'Started training {name}.')\n",
    "    start = time()\n",
    "    est = fitEstimatorWithSamplerWithoutCV(\n",
    "        X_train, y_train, estimator = estimator)\n",
    "    end = time()\n",
    "    print(f'Finished training {name} in {end-start} seconds. \\n')\n",
    "    fit_estimators.append(est)\n",
    "\n",
    "# Finished training LR in 806.5017838478088 seconds. \n",
    "\n",
    "# Finished training DT in 19.58332395553589 seconds. \n",
    "\n",
    "# Finished training ANN in 78.81134724617004 seconds. \n",
    "\n",
    "# Finished training SVC in 20.717212915420532 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearSVC performs the best\n",
    "for e in fit_estimators:\n",
    "    scoreBalancedEstimator(e, X_test, y_test)\n",
    "    \n",
    "# [[214504 156749]\n",
    "#  [ 35684  54389]]\n",
    "#                    pre       rec       spe        f1       geo       iba       sup\n",
    "\n",
    "#         0.0       0.86      0.58      0.60      0.69      0.59      0.35    371253\n",
    "#         1.0       0.26      0.60      0.58      0.36      0.59      0.35     90073\n",
    "\n",
    "# avg / total       0.74      0.58      0.60      0.63      0.59      0.35    461326\n",
    "\n",
    "# [[211599 159654]\n",
    "#  [ 38973  51100]]\n",
    "#                    pre       rec       spe        f1       geo       iba       sup\n",
    "\n",
    "#         0.0       0.84      0.57      0.57      0.68      0.57      0.32    371253\n",
    "#         1.0       0.24      0.57      0.57      0.34      0.57      0.32     90073\n",
    "\n",
    "# avg / total       0.73      0.57      0.57      0.61      0.57      0.32    461326\n",
    "\n",
    "# [[254099 117154]\n",
    "#  [ 42728  47345]]\n",
    "#                    pre       rec       spe        f1       geo       iba       sup\n",
    "\n",
    "#         0.0       0.86      0.68      0.53      0.76      0.60      0.37    371253\n",
    "#         1.0       0.29      0.53      0.68      0.37      0.60      0.35     90073\n",
    "\n",
    "# avg / total       0.75      0.65      0.56      0.68      0.60      0.36    461326\n",
    "\n",
    "# [[244589 126664]\n",
    "#  [ 32902  57171]]\n",
    "#                    pre       rec       spe        f1       geo       iba       sup\n",
    "\n",
    "#         0.0       0.88      0.66      0.63      0.75      0.65      0.42    371253\n",
    "#         1.0       0.31      0.63      0.66      0.42      0.65      0.42     90073\n",
    "\n",
    "# avg / total       0.77      0.65      0.64      0.69      0.65      0.42    461326\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
