{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from joblib import dump\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, IterativeImputer\n",
        "# from sklearn.impute import MissingIndicator\n",
        "# from sklearn.pipeline import FeatureUnion, make_pipeline\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "\n",
        "# %% \n",
        "# Load data\n",
        "df = pd.read_csv('loan-data-with-missing-vals.csv.gzip', compression = 'gzip')\n",
        "\n",
        "# %% \n",
        "# Check missing values\n",
        "missing = df.isna().sum().apply(lambda x: x/df.shape[0] * 100)\n",
        "print(missing[missing > 0].sort_values(ascending = False))\n",
        "\n",
        "# all_util                 45.506037\n",
        "# mths_since_recent_inq    12.441885  # consider dropping this?\n",
        "# employment_len            6.299746  \n",
        "# bc_util                   3.695852\n",
        "# percent_bc_gt_75          3.664943\n",
        "# pct_tl_nvr_dlq            3.638120\n",
        "# num_accts_ever_120_pd     3.629842\n",
        "# num_tl_30dpd              3.629842\n",
        "# num_tl_90g_dpd_24m        3.629842\n",
        "# pub_rec_bankruptcies      0.037466\n",
        "# tax_liens                 0.002096\n",
        "\n",
        "# %% \n",
        "# Plot vars with missing values\n",
        "cols_with_missing_vals = missing[missing > 0]\\\n",
        "    .sort_values(ascending = False).index\n",
        "\n",
        "for col in cols_with_missing_vals:\n",
        "    g = sns.histplot(x = df[col])\n",
        "    plt.show()\n",
        "    g.clear()\n",
        "\n",
        "# %% \n",
        "# Imputing all_util with mean\n",
        "i = SimpleImputer(strategy = 'mean')\n",
        "df['all_util'] = i.fit_transform(df['all_util'].values.reshape(-1, 1))\n",
        "\n",
        "\n",
        "# %% \n",
        "# Impute with IterativeImputer + DecisionTreeRegressor\n",
        "e = DecisionTreeRegressor(max_features = 'sqrt', \n",
        "                          max_depth = 3, random_state = 111)\n",
        "imp = IterativeImputer(estimator = e)\n",
        "temp = df.select_dtypes('float64').copy()\n",
        "imp.fit(temp)\n",
        "imputed = imp.transform(temp)\n",
        "\n",
        "\n",
        "# %% \n",
        "# Rebuild X, separate y\n",
        "imputed_num = pd.DataFrame(imputed, \n",
        "                           columns = df.dtypes[df.dtypes == 'float64'].index)\n",
        "cat_vars = df[df.columns[df.dtypes == 'object']]\n",
        "dummies = pd.get_dummies(cat_vars)\n",
        "y = imputed_num['y']\n",
        "imputed_num.drop('y', axis = 1, inplace = True)\n",
        "\n",
        "X = pd.concat([imputed_num, dummies], axis = 1)\n",
        "\n",
        "# X.to_csv('X.csv.gzip', compression = 'gzip', index = None)\n",
        "# y.to_csv('y.csv', index = None)\n",
        "\n",
        "# %% \n",
        "# Scale values + train_test_split\n",
        "scaler = MinMaxScaler(feature_range = (0, 1))\n",
        "scaler.fit(X)\n",
        "scaled_vars = pd.DataFrame(scaler.transform(X), \n",
        "                           columns = X.columns)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    scaled_vars, y, train_size = 0.8, random_state = 111, shuffle = True)\n",
        "\n",
        "# %% \n",
        "# train LogisticRegression\n",
        "lr = LogisticRegression(solver = 'saga', n_jobs = -1, max_iter = 500)\n",
        "lr.fit(X_train, y_train)\n",
        "lr_pred = lr.predict(X_test)\n",
        "lr.score(X_test, y_test) \n",
        "\n",
        "confused = confusion_matrix(y_true = y_test, y_pred = lr_pred)\n",
        "print(confused)\n",
        "print(classification_report(y_test, lr_pred))\n",
        "\n",
        "# 0.807356759284643\n",
        "\n",
        "# [[295472   3800]\n",
        "#  [ 67876   4918]]\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#          0.0       0.81      0.99      0.89    299272\n",
        "#          1.0       0.56      0.07      0.12     72794\n",
        "\n",
        "#     accuracy                           0.81    372066\n",
        "#    macro avg       0.69      0.53      0.51    372066\n",
        "# weighted avg       0.76      0.81      0.74    372066"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# train RandomForest\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators = 100,\n",
        "    criterion = 'gini',\n",
        "    max_depth = None,\n",
        "    min_samples_split = 2,\n",
        "    min_samples_leaf = 1,\n",
        "    min_weight_fraction_leaf = 0.0,\n",
        "    bootstrap = True,\n",
        "    oob_score = True,\n",
        "    n_jobs = -1,\n",
        "    random_state = 111)\n",
        "\n",
        "rf.fit(X_train, y_train.values.reshape(-1))\n",
        "rf_pred = rf.predict(X_test)\n",
        "\n",
        "print(rf.score(X_test, y_test))\n",
        "confused = confusion_matrix(y_true = y_test, y_pred = rf_pred)\n",
        "print(confused)\n",
        "print(classification_report(y_test, rf_pred))\n",
        "\n",
        "# 0.8197067187004456\n",
        "\n",
        "# [[296043   3229]\n",
        "#  [ 63852   8942]]\n",
        "\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#          0.0       0.82      0.99      0.90    299272\n",
        "#          1.0       0.73      0.12      0.21     72794\n",
        "\n",
        "#     accuracy                           0.82    372066\n",
        "#    macro avg       0.78      0.56      0.55    372066\n",
        "# weighted avg       0.81      0.82      0.76    372066\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# save model \n",
        "dump(rf, 'rf_trained.joblib', compress = 3) \n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}